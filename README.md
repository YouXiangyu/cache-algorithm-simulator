# CAPSA - 缓存算法性能模拟器与分析器

- 创建/更新时间：2025-01-21

## 简介

CAPSA 是一个轻量级缓存性能模拟器，用于在相同的访问序列上比较 ARC、LRU、LFU、FIFO、2Q 和理论最优 OPT 算法。所有内置负载由 `capsa/trace_suite.py` 使用基于函数的脚本动态生成，无需预生成的跟踪文件。

## 核心特性

- **固定缓存大小**：32 页
- **固定请求数**：每个负载 50000 次请求
- **9 个内置负载**：覆盖不同算法的优势场景
- **两种使用模式**：带数字参数的命令行或交互式 CLI 菜单
- **动态生成**：所有负载实时生成，保证可重现性
- **简单设计**：使用循环、条件分支和均匀分布，避免复杂随机

## 系统要求

- Python 3.10+

## 快速启动

### 命令行:

```bash
# 克隆或下载项目后，直接运行
python main.py
```

### 运行示例

```bash
# 方式1：交互式菜单（推荐）
python main.py

# 方式2：命令行参数
python main.py -1          # 运行负载 1
python main.py -1 -3 -5    # 运行负载 1、3 和 5
python main.py -9          # 运行负载 9

# 方式3：运行所有负载并显示汇总表（推荐用于快速对比）
python main.py -all        # 运行所有负载，显示美观的命中率汇总表

# 生成实际负载（可选）
python generate_fixed_traces.py
```

交互式菜单将显示所有 9 个负载及其特征，您可以：
- 输入用空格或逗号分隔的负载编号（例如，`1 3 5` 或 `1,3,5`）
- 按 Enter 运行所有负载
- 选择多个负载进行批量分析

## 9 种负载详解

### WL01-WL02: 有利于LFU的负载（频率模式）

#### WL01_STATIC_FREQ：静态频率模式

**设计思路**：
- 热页：页面1-5，每个访问100次/轮（共500次/轮）
- 冷页：页面6-105，每个访问1次/轮（共100次/轮）
- 每轮600次请求，共约83轮

**关键特征**：
- 少量热页高频访问，大量冷页低频访问
- LFU能锁定高频数据，LRU会被冷页清洗

**预期命中率**：LFU ~75%, ARC ~60%, LRU ~15%, 2Q ~20%

#### WL02_FREQ_BALANCED：频率平衡模式

**设计思路**：
- 热页：页面1-20，每个访问10次/轮（共200次/轮）
- 温页：页面21-60，每个访问1次/轮（共40次/轮）
- 每轮240次请求，共约208轮

**关键特征**：
- 工作集刚好等于缓存大小，测试频率vs空间平衡
- 热集大小=20，接近缓存32，LFU能识别频率优势

**预期命中率**：LFU ~65%, ARC ~55%, LRU ~25%, 2Q ~30%

### WL03-WL04: 有利于LRU的负载（最近使用模式）

#### WL03_STATIC_SW：静态滑动窗口

**设计思路**：
- 窗口大小28（略小于缓存32），每次移动1位
- 纯最近使用模式，无频率信息
- 窗口循环访问，每次滑动1页

**关键特征**：
- LRU能完美跟踪最近使用的28页，LFU无法利用频率信息

**预期命中率**：LRU ~70%, ARC ~60%, LFU ~10%, 2Q ~15%

#### WL04_OSC_SW：震荡滑动窗口

**设计思路**：
- 窗口大小在25和45之间震荡
- 小窗口阶段：窗口25（小于缓存32），持续2500次请求
- 大窗口阶段：窗口45（大于缓存32），持续2500次请求

**关键特征**：
- 小窗口时LRU表现好，大窗口时LRU仍能跟踪最近使用

**预期命中率**：LRU ~60%, ARC ~50%, LFU ~8%, 2Q ~12%

### WL05: 有利于FIFO的负载（顺序访问模式）

#### WL05_SEQUENTIAL_HOT：顺序访问+热集模式

**设计思路**：
- 热集：页面1-5，每个访问10次/轮（共50次/轮）
- 顺序：页面6-37，每个访问1次/轮（共32次/轮，刚好填满缓存）
- 每轮82次请求，共约609轮

**关键特征**：
- 热集访问频率适中，FIFO能保留它们（因为热集先加载）
- 顺序访问会按FIFO顺序淘汰，但热集因为访问频率适中，能保持在缓存中
- LRU会被顺序访问干扰（最近访问的是顺序页面，会淘汰热集）
- LFU会被顺序访问干扰（顺序页面访问次数少但会进入缓存，干扰频率统计）

**预期命中率**：FIFO ~70%, ARC ~60%, LRU ~30%, LFU ~50%, 2Q ~35%

### WL06-WL07: 有利于2Q的负载（扫描+热集模式）

#### WL06_SCAN_HOT_MIXED：扫描+热集混合

**设计思路**：
- 每100次请求：20次热集访问（页面1-3循环），80次扫描访问（页面1000+顺序，每个只访问一次）
- 热集会重复访问（会被2Q的Am队列保留），扫描是一次性的（会被2Q的A1in队列过滤）

**关键特征**：
- 2Q的A1in队列（16页）能过滤扫描数据，不会污染Am队列（16页）中的热数据
- LRU会被扫描干扰（扫描数据会进入缓存，清洗热数据）

**预期命中率**：2Q ~75%, ARC ~50%, LRU ~15%, LFU ~20%, FIFO ~15%

#### WL07_SCAN_SANDWICH：扫描三明治模式

**设计思路**：
- 阶段1：扫描页面1000-20000，每100次扫描夹杂2次热集（10000次请求）
- 阶段2：热集页面1-3（20000次请求，建立工作集）
- 阶段3：扫描页面20001-40000，每100次扫描夹杂2次热集（10000次请求）
- 阶段4：热集页面1-3（剩余请求，测试恢复能力）

**关键特征**：
- 2Q的A1in队列能过滤扫描数据，Am队列能保留热数据
- 扫描期间热集访问频率低，但2Q能识别并保留它们
- LRU会被扫描干扰（扫描数据会清洗热数据）

**预期命中率**：2Q ~80%, ARC ~60%, LRU ~25%, LFU ~30%, FIFO ~25%

### WL08-WL09: 有利于ARC的负载（自适应模式）

#### WL08_ADAPTIVE_FREQ_RECENCY：自适应频率-最近使用模式

**设计思路**：
- 阶段A（频率）：页面1-10循环访问（100次请求）
- 阶段B（最近使用）：滑动窗口32（32次请求）
- A和B交替

**关键特征**：
- ARC能在频率和最近使用之间自适应
- LFU在A阶段表现好，LRU在B阶段表现好，但ARC能在两者之间自适应

**预期命中率**：ARC ~65%, LFU ~50%（在A阶段好）, LRU ~55%（在B阶段好）, 2Q ~45%

#### WL09_ADAPTIVE_MIXED：自适应混合模式

**设计思路**：
- 每5000次请求切换模式：
  * 模式1：频率模式（页面1-5高频，页面6-20低频）
  * 模式2：最近使用模式（滑动窗口30）
  * 模式3：扫描+热集（每50次扫描夹杂5次热集）

**关键特征**：
- ARC能适应不同模式，其他算法只能适应一种

**预期命中率**：ARC ~60%, 其他算法 ~30-50%（取决于当前模式）

## 负载对比表

| # | 键 | 类别 | 核心特征 | 最适合算法 | 关键测试点 |
|---|-----|----------|----------------|------------|------------|
| 1 | WL01_STATIC_FREQ | LFU | 少量热页高频访问，大量冷页低频访问 | LFU | 频率偏向 |
| 2 | WL02_FREQ_BALANCED | LFU | 工作集等于缓存大小，频率vs空间平衡 | LFU | 频率与空间平衡 |
| 3 | WL03_STATIC_SW | LRU | 滑动窗口28（略小于缓存32） | LRU | 最近使用模式 |
| 4 | WL04_OSC_SW | LRU | 窗口大小在25和45之间震荡 | LRU | 工作集压力 |
| 5 | WL05_SEQUENTIAL_HOT | FIFO | 顺序访问+热集，热集先加载 | FIFO | 顺序访问干扰 |
| 6 | WL06_SCAN_HOT_MIXED | 2Q | 大量一次性扫描+少量重复热集 | 2Q | 扫描抗性 |
| 7 | WL07_SCAN_SANDWICH | 2Q | 扫描-热-扫描-热三明治模式 | 2Q | 重复刷新恢复 |
| 8 | WL08_ADAPTIVE_FREQ_RECENCY | ARC | 频率和最近使用阶段交替 | ARC | 自适应能力 |
| 9 | WL09_ADAPTIVE_MIXED | ARC | 多种模式每5000次请求切换 | ARC | 复杂自适应 |

## 使用 `-all` 参数快速对比

使用 `python main.py -all` 可以运行所有9个负载，并生成美观的命中率汇总表：

```
命中率汇总表（%）

负载      LRU      LFU     FIFO      ARC      OPT       2Q
----------------------------------------------------------------
WL01     15.23    75.12    15.23    60.45    96.78    20.34
WL02     25.67    65.34    25.67    55.12    98.23    30.45
...
```

这个表格可以快速对比不同算法在各个负载下的表现，便于发现各算法的优势和劣势。

## 核心组件

### 主要文件

#### `main.py`
主入口点，提供命令行接口。支持三种模式：
- **数字参数模式**：使用 `-1`, `-2` 等参数直接指定负载
- **交互式菜单模式**：不带参数运行，显示所有负载供选择
- **汇总模式**：使用 `-all` 参数运行所有负载并显示汇总表

主要功能：
- 解析命令行参数或显示交互菜单
- 调用 `trace_suite.py` 生成负载序列
- 使用 `simulator.py` 运行模拟
- 使用 `metrics.py` 生成性能报告

#### `generate_fixed_traces.py`
可选工具，将动态生成的负载序列导出为文本文件。生成的 `.trace` 文件保存在 `traces/` 目录中，可用于外部分析或调试。

### 核心模块（`capsa/`）

#### `cache_base.py`
定义统一的缓存接口 `Cache` 抽象基类。所有缓存算法必须实现：
- `access(page_id: int) -> bool`：访问页面，返回命中（True）或未命中（False）
- `get_stats() -> Dict[str, int]`：返回内部统计信息（如命中/未命中计数）

这确保了所有算法具有统一的接口，便于在相同条件下进行比较。

#### `capsa/caches/`
包含 6 种缓存算法的独立实现：
- **`lru.py`**：最近最少使用（LRU）算法，基于 `OrderedDict` 实现 O(1) 操作
- **`lfu.py`**：最不常用（LFU）算法，按访问频率和 LRU 共同淘汰
- **`fifo.py`**：先进先出（FIFO）算法，使用队列实现
- **`arc.py`**：自适应替换缓存（ARC），实现自适应的 LRU/LFU 混合策略
- **`two_q.py`**：2Q 双队列算法，利用 FIFO 热身队列与 LRU 主队列结合
- **`opt.py`**：理论最优（OPT）算法，需要预知未来访问序列

每个实现都是独立的，可以单独测试和优化。

#### `simulator.py`
模拟器核心，负责执行模拟过程：
- `Simulator` 类：顺序读取跟踪序列，将每个页面访问传递给缓存算法
- `SimulationResult` 数据类：记录模拟结果，包括命中率、未命中数、执行时间等
- 使用 `time.perf_counter_ns()` 测量算法开销（非实际 I/O 时间）

#### `metrics.py`
性能指标收集器和报告生成器：
- `MetricsCollector` 类：将 `SimulationResult` 转换为人类可读的报告
- `ReportConfig` 数据类：配置报告格式和内容
- 生成包含命中率排名、运行时间排名等信息的详细报告

#### `trace_suite.py`
负载定义和生成模块，这是项目的核心：
- 定义 9 个固定负载的生成函数
- 每个负载使用函数式编程方式生成，保证可重现性
- `TraceRecipe` 数据类：描述每个负载的元数据（键、文件名、类别、目标等）
- `repeat_function()`：辅助函数，用于重复执行某个函数
- `trim_to_target()`：辅助函数，确保生成的序列长度恰好为 50000

## 注意事项

- 所有负载都是动态生成的，不需要预生成的跟踪文件
- 所有模拟的缓存大小固定为 32 页
- 每个负载生成恰好 50000 次请求
- 所有负载使用简单的循环、条件分支和均匀分布，避免复杂随机
- 确保不同算法命中率差异明显（10%、30%、60%等），便于对比分析
- 代码注释为中文，便于理解和维护
